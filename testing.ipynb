{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f59d02ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\mhmza\\anaconda3\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n",
      "pygame 2.5.2 (SDL 2.28.3, Python 3.11.5)\n",
      "Hello from the pygame community. https://www.pygame.org/contribute.html\n",
      "WARNING:tensorflow:From C:\\Users\\mhmza\\anaconda3\\Lib\\site-packages\\keras\\src\\backend.py:1398: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\mhmza\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\normalization\\batch_normalization.py:979: The name tf.nn.fused_batch_norm is deprecated. Please use tf.compat.v1.nn.fused_batch_norm instead.\n",
      "\n",
      "1/1 [==============================] - 1s 779ms/step\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 51ms/step\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 48ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 48ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 51ms/step\n",
      "1/1 [==============================] - 0s 123ms/step\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 61ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 53ms/step\n",
      "1/1 [==============================] - 0s 157ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 80ms/step\n",
      "1/1 [==============================] - 0s 140ms/step\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 51ms/step\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 64ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 49ms/step\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "1/1 [==============================] - 0s 46ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 48ms/step\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 54ms/step\n",
      "1/1 [==============================] - 0s 67ms/step\n",
      "1/1 [==============================] - 0s 62ms/step\n",
      "1/1 [==============================] - 0s 48ms/step\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "1/1 [==============================] - 0s 48ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "1/1 [==============================] - 0s 54ms/step\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "1/1 [==============================] - 0s 46ms/step\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "1/1 [==============================] - 0s 81ms/step\n",
      "1/1 [==============================] - 0s 57ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 49ms/step\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 40ms/step\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "1/1 [==============================] - 0s 58ms/step\n",
      "1/1 [==============================] - 0s 51ms/step\n",
      "1/1 [==============================] - 0s 101ms/step\n",
      "1/1 [==============================] - 0s 82ms/step\n",
      "1/1 [==============================] - 0s 197ms/step\n",
      "1/1 [==============================] - 0s 70ms/step\n",
      "1/1 [==============================] - 0s 62ms/step\n",
      "1/1 [==============================] - 0s 57ms/step\n",
      "1/1 [==============================] - 0s 52ms/step\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "1/1 [==============================] - 0s 80ms/step\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "1/1 [==============================] - 0s 59ms/step\n"
     ]
    }
   ],
   "source": [
    "from keras.models import load_model\n",
    "from keras.preprocessing.image import img_to_array\n",
    "import cv2\n",
    "import numpy as np\n",
    "import tkinter as tk\n",
    "from PIL import Image, ImageTk\n",
    "import pygame\n",
    "import os\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.backends.backend_tkagg import FigureCanvasTkAgg\n",
    "from tkinter import ttk\n",
    "\n",
    "# Initialize pygame mixer\n",
    "pygame.mixer.init()\n",
    "\n",
    "# Define the face cascade classifier\n",
    "face_classifier = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')\n",
    "\n",
    "# Load the saved model\n",
    "classifier = load_model('./Emotion_Detection.h5')\n",
    "\n",
    "# Define the emotion labels and colors\n",
    "class_labels = ['Angry', 'Happy', 'Neutral', 'Sad', 'Surprise']\n",
    "colors = ['red', 'green', 'blue', 'purple', 'orange']\n",
    "\n",
    "# Initialize Tkinter window for webcam feed\n",
    "window = tk.Tk()\n",
    "window.title(\"Webcam Feed\")\n",
    "\n",
    "# Create a Tkinter label to display the video feed\n",
    "panel = tk.Label(window)\n",
    "panel.pack(padx=10, pady=10)\n",
    "\n",
    "# Create a Tkinter label to display the predicted emotion\n",
    "display_label = tk.Label(window, text=\"Emotion: None\", font=(\"Helvetica\", 16))\n",
    "display_label.pack()\n",
    "\n",
    "# Initialize Tkinter window for probability graph\n",
    "graph_window = tk.Tk()\n",
    "graph_window.title(\"Emotion Probability Graph\")\n",
    "\n",
    "# Create a frame for the probability graph\n",
    "graph_frame = tk.Frame(graph_window)\n",
    "graph_frame.pack(padx=11, pady=11)\n",
    "\n",
    "# Initialize Matplotlib figure for the probabilities graph\n",
    "fig, ax = plt.subplots(nrows=5, figsize=(5, 7))  # Adjust the number of rows based on the number of emotions\n",
    "canvas = FigureCanvasTkAgg(fig, master=graph_frame)\n",
    "canvas_widget = canvas.get_tk_widget()\n",
    "canvas_widget.pack()\n",
    "\n",
    "# # Initialize Tkinter window for song selection\n",
    "# song_window = tk.Toplevel(window)\n",
    "# song_window.title(\"Song Selection\")\n",
    "\n",
    "# # Create a label for the song selection\n",
    "# song_label = tk.Label(song_window, text=\"Select Song for Happy:\")\n",
    "# song_label.pack()\n",
    "\n",
    "# # Create a dropdown menu for song selection\n",
    "# happy_songs = ['happy_song1.mp3', 'happy_song2.mp3', 'happy_song3.mp3']  # Add your songs here\n",
    "# selected_happy_song = tk.StringVar(song_window)\n",
    "# selected_happy_song.set(happy_songs[0])  # Set the default song\n",
    "# happy_song_dropdown = ttk.Combobox(song_window, textvariable=selected_happy_song, values=happy_songs)\n",
    "# happy_song_dropdown.pack()\n",
    "\n",
    "# Initialize Tkinter window for static emotion distribution graph\n",
    "static_graph_window = tk.Toplevel(window)\n",
    "static_graph_window.title(\"Static Emotion Distribution Graph\")\n",
    "\n",
    "# Create a frame for the static emotion distribution graph\n",
    "static_graph_frame = tk.Frame(static_graph_window)\n",
    "static_graph_frame.pack(padx=11, pady=11)\n",
    "\n",
    "# Initialize Matplotlib figure for the static emotion distribution\n",
    "static_fig, static_ax = plt.subplots(figsize=(8, 4))\n",
    "static_canvas = FigureCanvasTkAgg(static_fig, master=static_graph_frame)\n",
    "static_canvas_widget = static_canvas.get_tk_widget()\n",
    "static_canvas_widget.pack()\n",
    "\n",
    "# Initialize emotion count dictionary to store the count of each emotion\n",
    "emotion_count = {label: 0 for label in class_labels}\n",
    "\n",
    "# Flag to check if the initial duration has passed\n",
    "initial_duration_passed = False\n",
    "\n",
    "# Function to update the static emotion distribution graph\n",
    "def update_static_graph():\n",
    "    if not initial_duration_passed:\n",
    "        static_ax.clear()\n",
    "        static_ax.bar(class_labels, emotion_count.values(), color=colors)\n",
    "        static_ax.set_ylim([0, observation_duration])\n",
    "        static_ax.set_ylabel('Total Time (s)')\n",
    "        static_ax.set_xlabel('Emotion')\n",
    "        static_ax.set_title('Emotion Distribution Over Time')\n",
    "        static_canvas.draw()\n",
    "\n",
    "# Function to update the Tkinter window with the probabilities graph\n",
    "def update_graph(preds):\n",
    "    global display_label, ax  # Declare display_label and ax as global variables\n",
    "    for i, emotion in enumerate(class_labels):\n",
    "        ax[i].clear()\n",
    "        ax[i].barh(emotion, preds[i], color=colors[i])\n",
    "        ax[i].set_xlim([0, 1])\n",
    "        ax[i].set_xlabel('Probability')\n",
    "        ax[i].set_title(emotion)\n",
    "\n",
    "    canvas.draw()\n",
    "\n",
    "# Function to update the emotion count based on the detected emotion\n",
    "def update_emotion_count(emotion):\n",
    "    emotion_count[emotion] += 1\n",
    "    update_static_graph()\n",
    "\n",
    "# Function to process each frame and update the GUI\n",
    "def process_frame():\n",
    "    global start_time, observation_duration, highest_emotion, music_playing, initial_duration_passed\n",
    "    current_time = time.time()\n",
    "\n",
    "    # Grab a single frame of video\n",
    "    ret, frame = cap.read()\n",
    "    labels = []\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    faces = face_classifier.detectMultiScale(gray, 1.3, 5)\n",
    "\n",
    "    # Check if any faces are detected\n",
    "    if len(faces) > 0:\n",
    "        for (x, y, w, h) in faces:\n",
    "            cv2.rectangle(frame, (x, y), (x+w, y+h), (255, 0, 0), 2)\n",
    "            roi_gray = gray[y:y+h, x:x+w]\n",
    "            roi_gray = cv2.resize(roi_gray, (48, 48), interpolation=cv2.INTER_AREA)\n",
    "\n",
    "            if np.sum([roi_gray]) != 0:\n",
    "                roi = roi_gray.astype('float') / 255.0\n",
    "                roi = img_to_array(roi)\n",
    "                roi = np.expand_dims(roi, axis=0)\n",
    "\n",
    "                # make a prediction on the ROI, then lookup the class\n",
    "                preds = classifier.predict(roi)[0]\n",
    "                label = class_labels[preds.argmax()]\n",
    "                label_position = (x, y)\n",
    "                cv2.putText(frame, label, label_position, cv2.FONT_HERSHEY_SIMPLEX, 2, (0, 255, 0), 3)\n",
    "\n",
    "                # Update the Tkinter window with the video feed\n",
    "                display_label.config(text=f\"Emotion: {label}\")\n",
    "\n",
    "                # Update the graph\n",
    "                update_graph(preds)\n",
    "\n",
    "                # Update the static graph and emotion count only for the initial duration\n",
    "                if not initial_duration_passed:\n",
    "                    update_emotion_count(label)\n",
    "\n",
    "                # Check if the observation duration is reached\n",
    "                if current_time - start_time >= observation_duration:\n",
    "                    # Play music based on the detected emotion\n",
    "                    play_music(label)\n",
    "\n",
    "                    # Keep track of the highest emotion during the observation\n",
    "                    highest_emotion = label\n",
    "\n",
    "                    # Set the flag to indicate that the initial duration has passed\n",
    "                    initial_duration_passed = True\n",
    "    else:\n",
    "        # Display the \"No Face Found\" message\n",
    "        cv2.putText(frame, 'No Face Found', (20, 60), cv2.FONT_HERSHEY_SIMPLEX, 2, (0, 255, 0), 3)\n",
    "        display_label.config(text=\"Emotion: None\")\n",
    "\n",
    "    # Display the processed frame in the Tkinter window\n",
    "    photo = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "    photo = Image.fromarray(photo)\n",
    "    photo = ImageTk.PhotoImage(image=photo)\n",
    "    panel.config(image=photo)\n",
    "    panel.image = photo\n",
    "\n",
    "    # Call the function again after a delay\n",
    "    window.after(10, process_frame)\n",
    "\n",
    "\n",
    "# Function to play music based on the detected emotion\n",
    "def play_music(emotion):\n",
    "    global music_playing\n",
    "\n",
    "    # Define the path to the music files\n",
    "    music_folder = './music'\n",
    "\n",
    "    # Map emotions to corresponding music files\n",
    "    music_mapping = {\n",
    "        'Angry': 'angry_music.mp3',\n",
    "#         'Happy': selected_happy_song.get(),  \n",
    "        'Happy': 'happy_music.mp3',\n",
    "        'Neutral': 'neutral_music.mp3',\n",
    "        'Sad': 'sad_music.mp3',\n",
    "        'Surprise': 'surprise_music.mp3',\n",
    "    }\n",
    "\n",
    "    # Get the corresponding music file for the detected emotion\n",
    "    music_file = music_mapping.get(emotion)\n",
    "\n",
    "    if music_file:\n",
    "        # Join the music folder path and music file name\n",
    "        music_path = os.path.join(music_folder, music_file)\n",
    "\n",
    "        # Check if music is currently playing\n",
    "        if not music_playing:\n",
    "            # Play the music\n",
    "            pygame.mixer.music.load(music_path)\n",
    "            pygame.mixer.music.play()\n",
    "            music_playing = True\n",
    "\n",
    "        # Check if the music has finished playing\n",
    "        elif not pygame.mixer.music.get_busy():\n",
    "            # Restart the music\n",
    "            pygame.mixer.music.play()\n",
    "\n",
    "# Open a connection to the camera (camera index 0 by default)\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "# Set the observation duration (in seconds)\n",
    "observation_duration = 5  \n",
    "start_time = time.time()\n",
    "\n",
    "# Variable to keep track of the highest emotion during observation\n",
    "highest_emotion = None\n",
    "\n",
    "# Variable to track whether music is currently playing\n",
    "music_playing = False\n",
    "\n",
    "# Start processing frames for the webcam feed\n",
    "window.after(10, process_frame)\n",
    "\n",
    "# Start Tkinter main loop for all windows\n",
    "window.mainloop()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52b81d58",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
